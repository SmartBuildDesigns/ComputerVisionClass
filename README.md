# Visi√≥n por Computadora: De P√≠xeles a Entendimiento ü§ñüëÅÔ∏è

¬°Bienvenidos a este curso de Visi√≥n por Computadora\! En este repositorio encontrar√°s una serie de tutoriales dise√±ados para llevarte desde los conceptos m√°s b√°sicos hasta t√©cnicas m√°s avanzadas, todo explicado de una manera sencilla y pr√°ctica para que cualquiera pueda empezar a "ense√±ar a ver" a las m√°quinas.

El objetivo es desmitificar el campo de la CV y darte las herramientas para que puedas crear tus propios proyectos.

-----

-----

## Calibraci√≥n de C√°mara: Corrigiendo la Visi√≥n del Mundo üì∏üìè

Empezamos con la calibraci√≥n porque es un paso fundamental y a menudo subestimado. Antes de poder medir o analizar una escena, debemos asegurarnos de que la c√°mara nos est√° dando una imagen geom√©tricamente correcta.

Calibrar una c√°mara es como **"graduarle la vista"**. Por la forma de sus lentes, las c√°maras distorsionan la realidad ver Figura 1. Lo que en el mundo real es una l√≠nea recta, en la imagen puede aparecer como una l√≠nea ligeramente curva. La calibraci√≥n nos permite encontrar un modelo matem√°tico para corregir estas imperfecciones.

Antes de poder medir distancias, reconstruir una escena en 3D o interactuar con el mundo, una c√°mara necesita entender su propia geometr√≠a. Calibrar una c√°mara es el proceso de descubrir sus caracter√≠sticas internas para traducir los p√≠xeles de una imagen a mediciones fiables del mundo real.

<figure>
  <img src="Fig2_Calibrate.png" alt="Fig1." />
  <figcaption> Fig.1 Ejemplos de distorsiones del lente. </figcaption>
</figure>

### El Modelo Matem√°tico: Puntos, P√≠xeles y Matrices

Para corregir las imperfecciones, primero necesitamos un modelo matem√°tico que describa c√≥mo una c√°mara ideal deber√≠a funcionar.

#### El Modelo Pinhole Ideal

El modelo m√°s simple y fundamental es el de la **c√°mara estenopeica (pinhole)**. Imagina una caja con un peque√±o orificio en un lado y una pel√≠cula fotogr√°fica en el lado opuesto. Los rayos de luz de un objeto en el mundo pasan a trav√©s del orificio y se proyectan de forma invertida en la pel√≠cula.

Para simplificar las matem√°ticas, solemos usar un modelo virtual donde el plano de la imagen se coloca *delante* del orificio (que llamamos **centro de proyecci√≥n**). De esta forma, la imagen no aparece invertida. La relaci√≥n clave, por semejanza de tri√°ngulos, es:

$$x = f \cdot \frac{X}{Z} \quad , \quad y = f \cdot \frac{Y}{Z}$$

Donde:

  * $(X, Y, Z)$ son las coordenadas de un punto 3D en el mundo real.
  * $(x, y)$ son las coordenadas del punto proyectado en el plano de la imagen.
  * $f$ es la **distancia focal** de la c√°mara. ver figura 2.

<figure>
  <img src="Fig1_Calibrate.png" alt="Fig2." />
  <figcaption> Fig.2 Q es el punto (X,Y,Z) en el mundo real, q es el punto (x,y) en el plano de la imagen y f es la distancia focal.</figcaption>
</figure>

#### Coordenadas Homog√©neas y la Matriz Intr√≠nseca (K)

Podemos expresar esta proyecci√≥n de forma matricial usando **coordenadas homog√©neas**, que a√±aden una dimensi√≥n extra para simplificar las transformaciones proyectivas. Esto nos permite encapsular las propiedades internas de la c√°mara en una √∫nica matriz 3x3 llamada **matriz de par√°metros intr√≠nsecos (K)**.

$$\begin{pmatrix} 
x_{pixel} \\
y_{pixel} \\ 
1 \end{pmatrix} = \begin{pmatrix} 
f_x & 0 & c_x \\
0 & f_y & c_y \\ 
0 & 0 & 1 \end{pmatrix} 
\begin{pmatrix} X_{cam} \\
Y_{cam} \\ 
Z_{cam} 
\end{pmatrix}$$

  * **$f\_x, f\_y$ (Distancia Focal en p√≠xeles):** El "zoom" de la lente, pero medido en unidades de p√≠xeles en los ejes X e Y. Es la combinaci√≥n de la distancia focal f√≠sica y el tama√±o de los p√≠xeles en el sensor.
  * **$c\_x, c\_y$ (Punto Principal):** El verdadero centro √≥ptico de la imagen. Es el punto en p√≠xeles donde el eje √≥ptico de la lente intersecta el sensor. Rara vez coincide con el centro exacto de la imagen.

Antes de continuar vamos a explicar m√°s a detalle que son las coordenadas homog√©neas.

Son una maniobra matem√°tica que nos permite simplificar las operaciones geom√©tricas, como las traslaciones, rotaciones y cambios de escala, represent√°ndolas todas como una √∫nica operaci√≥n: la multiplicaci√≥n de matrices.

## ¬øCual es el problema de las coordenadas cartesianas?

En un sistema de coordenadas cartesianas normal (el que usamos habitualmente con ejes X, Y, Z), algunas operaciones geom√©tricas son m√°s complicadas que otras.

* Una **rotaci√≥n** se puede expresar como una multiplicaci√≥n de matrices.
* Un **cambio de escala** (escalado) tambi√©n se puede expresar como una multiplicaci√≥n de matrices.
* Una **traslaci√≥n** (mover un objeto sin rotarlo) se expresa como una **suma** de vectores.

Este "problema" de tener que combinar sumas y multiplicaciones es inconveniente para las computadoras, especialmente para el hardware gr√°fico (GPUs) que est√° optimizado para realizar multiplicaciones de matrices de forma masiva y muy r√°pida.

## ¬øCu√°l es la soluci√≥n?: A√±adir una dimensi√≥n extra

Las coordenadas homog√©neas resuelven este problema a√±adiendo una dimensi√≥n extra a nuestros puntos, tradicionalmente llamada **w**.

* Un punto **2D** $(X, Y)$ se convierte en $(x, y, w)$.
* Un punto **3D** $(X, Y, Z)$ se convierte en $(x, y, z, w)$.

Para convertir de coordenadas cartesianas a homog√©neas, simplemente a√±adimos un 1 en la nueva coordenada `w`:

* $(X, Y) \rightarrow (X, Y, 1)$
* $(X, Y, Z) \rightarrow (X, Y, Z, 1)$

Para convertir de vuelta de homog√©neas a cartesianas, dividimos todas las coordenadas por `w` y descartamos la √∫ltima componente:

* $(x, y, w) \rightarrow (x/w, y/w)$
* $(x, y, z, w) \rightarrow (x/w, y/w, z/w)$

### ¬øPor qu√© funciona esto?

Al a√±adir esta dimensi√≥n extra, todas las transformaciones geom√©tricas (incluida la traslaci√≥n) se pueden expresar como una √∫nica multiplicaci√≥n de matrices.

**Ejemplo: Traslaci√≥n en 2D**

Imagina que quieres mover el punto $(X, Y)$ una distancia de $(T_x, T_y)$.

* **En coordenadas cartesianas:** $(X_{nuevo}, Y_{nuevo}) = (X + T_x, Y + T_y)$ (una suma).
* **En coordenadas homog√©neas:** Representamos la traslaci√≥n con una matriz y el punto como un vector. La operaci√≥n se convierte en una multiplicaci√≥n.

$$\begin{pmatrix} 
1 & 0 & T_x \\ 
0 & 1 & T_y \\
0 & 0 & 1 
\end{pmatrix} \begin{pmatrix}
X \\
Y \\
1 
\end{pmatrix} = \begin{pmatrix} 
X + T_x \\
Y + T_y \\
1 
\end{pmatrix}$$


El resultado, $(X + T_x, Y + T_y, 1)$, es el nuevo punto en coordenadas homog√©neas. Al convertirlo de vuelta a cartesianas, obtenemos $(X + T_x, Y + T_y)$, que es exactamente el resultado que quer√≠amos.

### El Punto en el Infinito

Una propiedad interesante de las coordenadas homog√©neas es que nos permiten representar el concepto de "puntos en el infinito". Si el valor de `w` es 0, al intentar convertir de vuelta a coordenadas cartesianas, tendr√≠amos que dividir por cero.

$$(x, y, 0) \rightarrow (\infty, \infty)$$

Esto es muy √∫til en gr√°ficos por computadora y visi√≥n por computadora para representar la direcci√≥n de los rayos de luz o l√≠neas paralelas que "se encuentran" en el infinito.

En resumen, las coordenadas homog√©neas son un sistema que, **al a√±adir una dimensi√≥n `w`**, nos permite **unificar todas las transformaciones geom√©tricas en una sola operaci√≥n de multiplicaci√≥n de matrices**, lo cual es computacionalmente muy eficiente.

Ahora si continuemos con el proceso de calibraci√≥n.

#### Par√°metros Extr√≠nsecos (R y T)

La matriz intr√≠nseca traduce puntos desde el sistema de coordenadas 3D *de la c√°mara* a la imagen 2D. Pero, ¬ød√≥nde est√° la c√°mara en el mundo? Los **par√°metros extr√≠nsecos** describen su posici√≥n y orientaci√≥n en el espacio. Consisten en:

  * Una **matriz de rotaci√≥n (R)** de 3x3 que define la orientaci√≥n de la c√°mara.
  * Un **vector de traslaci√≥n (T)** de 3x1 que define su posici√≥n.

Juntos, nos permiten transformar un punto del mundo real $(X\_w, Y\_w, Z\_w)$ al sistema de coordenadas de la c√°mara $(X\_c, Y\_c, Z\_c)$.

#### Distorsiones del Lente

Aqu√≠ es donde abandonamos el mundo ideal. Las lentes reales, especialmente las m√°s econ√≥micas ver Figura 3, no son perfectas e introducen distorsiones. Las principales son:

<figure>
  <img src="Fig3_Calibrate.png" alt="Fig3." />
  <figcaption> Fig.3 Ejemplo de como son las lentes econ√≥micas. </figcaption>
</figure>

1.  **Distorsi√≥n Radial:** Ocurre porque la lente curva m√°s los rayos de luz en los bordes que en el centro. Esto causa el famoso efecto "ojo de pez" o de "barril". Se modela con una serie de coeficientes $(k\_1, k\_2, k\_3)$.

<figure>
  <img src="Fig4_Calibrate.png" alt="Fig4." />
  <figcaption> Fig.4 Ejemplo de distorsi√≥n radial.</figcaption>
</figure>

2.  **Distorsi√≥n Tangencial:** Ocurre si la lente no est√° perfectamente paralela al sensor de la c√°mara. Se modela con dos coeficientes $(p\_1, p\_2)$.

<figure>
  <img src="Fig5_Calibrate.png" alt="Fig5." />
  <figcaption> Fig.5 Ejemplo de distorsi√≥n tangencial.</figcaption>
</figure>

El objetivo final de la calibraci√≥n es encontrar los valores precisos de la **matriz intr√≠nseca (K)** y los **cinco coeficientes de distorsi√≥n $(k\_1, k\_2, k\_3, p\_1, p\_2)$**.

### El Proceso Pr√°ctico con un Tablero de Ajedrez ‚ôüÔ∏è

Para encontrar todos estos par√°metros, necesitamos un objeto cuya geometr√≠a conozcamos a la perfecci√≥n. Un **tablero de ajedrez** es ideal porque es plano y sus esquinas internas forman una cuadr√≠cula perfectamente regular.

El proceso consiste en mostrarle a la c√°mara el tablero desde m√∫ltiples √°ngulos y distancias. OpenCV utiliza estas m√∫ltiples vistas para resolver el sistema de ecuaciones y encontrar los par√°metros de la c√°mara.

### Tutorial Pr√°ctico en C√≥digo

Aqu√≠ est√° el flujo completo para calibrar tu c√°mara.

#### Paso 1: Preparaci√≥n del Entorno

Instala la paqueteria necesaria para calibrar la c√°mara.
```bash
pip install opencv-python numpy 
```
```bash
pip install matplotlib
```
#### Paso 2: Recolectar las Im√°genes del Tablero

1.  Imprime un patr√≥n de tablero de ajedrez. Aqui puedes descargar un ejemplo. [Aqui.](checkerboardPattern.pdf)
2.  Toma entre 15-20 fotos del tablero desde diferentes √°ngulos. Aseg√∫rate de que el tablero llene diferentes partes de la vista de la c√°mara.
3.  Guarda todas las im√°genes en una carpeta.

#### Paso 3: C√≥digo de Adquisici√≥n autom√°tica

Visualiza el c√≥digo de adquisici√≥n. [ver adquisicion2D.py](adquisicion2D.py)

* El siguiente c√≥digo busca y controla la c√°mara conectada a la computadora.
* Despliega la imagen de video
* Busca el tablero (Hay que establecer correctamente las columnas y filas del tablero para que lo detecte)
* Mueve el tablero y empieza a capturar las imagenes y guardarlas. (Calibralo con los milimetros de movimiento entre mas alto los milimetros menor sensibilidad en el movimiento)
* Presiona "q" y finaliza.

```python
import cv2
import numpy as np
import os
import time

# --- 1. CONFIGURACI√ìN DEL TABLERO ---
# N√∫mero de esquinas INTERIORES del tablero (ej: un tablero 10x7 tiene 9x6 esquinas interiores)
CHESSBOARD_SIZE = (9, 6) # (columnas, filas)

# Criterios para la detecci√≥n y refinamiento de esquinas
criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)

# --- 2. CONFIGURACI√ìN PARA DETECCI√ìN DE MOVIMIENTO Y ADQUISICI√ìN ---
# Umbral de movimiento: Si el vector de traslaci√≥n (tvec) cambia en m√°s de este valor (mm), se considera movimiento.
# Ajusta este valor seg√∫n qu√© tan sensible quieres que sea la detecci√≥n de movimiento.
# Un valor m√°s peque√±o detectar√° movimientos sutiles.
MOVEMENT_THRESHOLD_MM = 1 # 10 mm = 1 cm de cambio en la posici√≥n
MIN_TIME_BETWEEN_CAPTURES_SEC = 1.0 # M√≠nimo tiempo en segundos entre capturas autom√°ticas

# --- 3. CONFIGURAR LA ADQUISICI√ìN DE VIDEO ---
cap = cv2.VideoCapture(0) # '0' para la c√°mara predeterminada (tu Logitech C922)

if not cap.isOpened():
    print("Error: No se pudo abrir la c√°mara. Aseg√∫rate de que est√© conectada y no en uso.")
    exit()

# Establecer resoluci√≥n (opcional, tu C922 soporta varias)
cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280) # Ejemplo de resoluci√≥n
cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720) # Ejemplo de resoluci√≥n
print(f"Resoluci√≥n actual de la c√°mara: {int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))}x{int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))}")


# --- 4. CONFIGURAR CARPETA DE SALIDA ---
output_dir = "imagenes_para_calibracion_auto"
os.makedirs(output_dir, exist_ok=True)
print(f"Las im√°genes se guardar√°n en: {os.path.abspath(output_dir)}")

# --- 5. PREPARAR PUNTOS DEL OBJETO 3D PARA solvePnP (solo para estimar pose y detectar movimiento) ---
# No necesitamos SQUARE_SIZE_MM preciso para esto, solo una escala relativa. Usaremos 1.0.
objp_for_pose = np.zeros((CHESSBOARD_SIZE[0] * CHESSBOARD_SIZE[1], 3), np.float32)
objp_for_pose[:, :2] = np.mgrid[0:CHESSBOARD_SIZE[0], 0:CHESSBOARD_SIZE[1]].T.reshape(-1, 2) * 1.0

# Una matriz de c√°mara de identidad y distorsi√≥n cero para solvePnP si no tenemos calibraci√≥n.
# Esto nos dar√° una estimaci√≥n de pose relativa, suficiente para detectar movimiento.
# ¬°IMPORTANTE! Estos NO son los par√°metros de calibraci√≥n reales.
dummy_mtx = np.eye(3, dtype=np.float32)
dummy_mtx[0,0] = dummy_mtx[1,1] = 800 # Valores iniciales estimados para una lente
dummy_mtx[0,2] = cap.get(cv2.CAP_PROP_FRAME_WIDTH) / 2
dummy_mtx[1,2] = cap.get(cv2.CAP_PROP_FRAME_HEIGHT) / 2
dummy_dist = np.zeros((4,1), dtype=np.float32)


# --- 6. VARIABLES DE ESTADO ---
image_count = 0
last_tvec = None # Almacena la traslaci√≥n del frame anterior
last_capture_time = time.time() # √öltimo momento en que se guard√≥ una imagen

# --- 7. BUCLE PRINCIPAL DE ADQUISICI√ìN ---
print("\nInstrucciones:")
print("  - Mueve el tablero de ajedrez frente a la c√°mara.")
print("  - Las im√°genes se guardar√°n autom√°ticamente cuando se detecte un movimiento significativo.")
print("  - Presiona 'q' para salir en cualquier momento.")

while(True):
    ret, frame = cap.read() # Captura un frame
    if not ret:
        print("Error al leer el frame. ¬øLa c√°mara sigue conectada?")
        break

    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    display_frame = frame.copy() # Hacemos una copia para dibujar sobre ella

    # Intenta encontrar las esquinas del tablero
    ret_corners, corners = cv2.findChessboardCorners(gray, CHESSBOARD_SIZE, None)

    if ret_corners == True:
        # Refina las esquinas para una mejor estimaci√≥n de pose
        corners2 = cv2.cornerSubPix(gray, corners, (11,11), (-1,-1), criteria)
        
        # Estima la pose del tablero (rvec y tvec)
        _, rvec, tvec = cv2.solvePnP(objp_for_pose, corners2, dummy_mtx, dummy_dist, flags=cv2.SOLVEPNP_ITERATIVE)

        # Dibuja las esquinas detectadas en verde
        cv2.drawChessboardCorners(display_frame, CHESSBOARD_SIZE, corners2, ret_corners)
        cv2.putText(display_frame, f"Tablero DETECTADO! (Imgs: {image_count})", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2, cv2.LINE_AA)

        current_time = time.time()
        
        # L√≥gica para la captura autom√°tica:
        # 1. Ya se ha capturado al menos una imagen antes (last_tvec no es None)
        # 2. Ha pasado suficiente tiempo desde la √∫ltima captura
        # 3. El tablero se ha movido significativamente
        if last_tvec is not None and \
           (current_time - last_capture_time > MIN_TIME_BETWEEN_CAPTURES_SEC):
            
            # Calcula la diferencia de traslaci√≥n
            movement_diff = np.linalg.norm(tvec - last_tvec) # Norma Euclidiana
            
            if movement_diff > MOVEMENT_THRESHOLD_MM:
                image_count += 1
                filename = os.path.join(output_dir, f"calib_image_{image_count:03d}.jpg")
                cv2.imwrite(filename, frame) # Guarda el frame ORIGINAL (sin dibujos)
                print(f"Imagen '{filename}' guardada. Movimiento: {movement_diff:.2f} mm")
                last_capture_time = current_time # Reinicia el temporizador
                # Opcional: Pausa visual para ver la captura
                # cv2.imshow('Capturada!', frame)
                # cv2.waitKey(200) # Muestra por 200ms
        
        last_tvec = tvec # Actualiza la pose anterior

    else:
        cv2.putText(display_frame, f"Buscando tablero... (Imgs: {image_count})", (10, 30),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 0, 255), 2, cv2.LINE_AA)
        last_tvec = None # Resetea la pose si el tablero no es visible

    # Mostrar el conteo de im√°genes guardadas
    cv2.putText(display_frame, f"Guardadas: {image_count}", (10, 60),
                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2, cv2.LINE_AA)


    # Mostrar el frame procesado
    cv2.imshow('Adquisicion Auto de Imagenes para Calibracion', display_frame)

    # --- Control de usuario ---
    key = cv2.waitKey(1) & 0xFF
    if key == ord('q'):
        break

# Liberar la c√°mara y cerrar ventanas
cap.release()
cv2.destroyAllWindows()
print(f"\nAdquisici√≥n de im√°genes finalizada. Total de im√°genes guardadas: {image_count}")
```


#### Paso 3: Calibraci√≥n y correcci√≥n de distorsi√≥n.

Visualiza el c√≥digo de calibraci√≥n y correci√≥n [ver calibracion.py](calib.py)

* Lee las imagenes guardadas de la adquisici√≥n.
* Calibra la c√°mara. (Mide el tama√±o de un cuadrado del tablero y anotalo en MM)
* Realiza la correci√≥n de la distorsi√≥n.
* Muestra la posici√≥n de la c√°mara y el tablero en un espacio en 3 dimensiones.

```python
import cv2
import numpy as np
import glob
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import os

# --- 1. CONFIGURACI√ìN INICIAL ---
# Define el tama√±o del tablero (n√∫mero de esquinas interiores)
CHESSBOARD_SIZE = (9, 6) # (columnas, filas)
# Tama√±o de cada cuadro del tablero en unidades reales (ej: mil√≠metros o cent√≠metros)
SQUARE_SIZE_MM = 25.0 # Por ejemplo, 25.0 mm por cuadro

# Criterios para la optimizaci√≥n de las esquinas (para cvFindCornerSubPix)
criteria = (cv2.TERM_CRITERIA_EPS + cv2.TERM_CRITERIA_MAX_ITER, 30, 0.001)

# --- 2. PREPARAR PUNTOS DEL MUNDO REAL Y PUNTOS DE LA IMAGEN ---
objp = np.zeros((CHESSBOARD_SIZE[0] * CHESSBOARD_SIZE[1], 3), np.float32)
objp[:,:2] = np.mgrid[0:CHESSBOARD_SIZE[0], 0:CHESSBOARD_SIZE[1]].T.reshape(-1,2) * SQUARE_SIZE_MM

objpoints = [] # Puntos 3D
imgpoints = [] # Puntos 2D

# --- 3. DETECCI√ìN Y REFINAMIENTO DE ESQUINAS ---
images = glob.glob('imagenes_para_calibracion_auto/*.jpg')

found_images = []

for fname in images:
    img = cv2.imread(fname)
    if img is None:
        print(f"Advertencia: No se pudo cargar la imagen {fname}. Saltando.")
        continue

    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    ret, corners = cv2.findChessboardCorners(gray, CHESSBOARD_SIZE, None)

    if ret == True:
        objpoints.append(objp)
        corners2 = cv2.cornerSubPix(gray, corners, (11,11), (-1,-1), criteria)
        imgpoints.append(corners2)
        found_images.append(fname)
        # No imprimimos aqu√≠ para no saturar la consola, se imprime el resumen al final
    # else:
    #    print(f"‚ùå Tablero NO detectado en: {os.path.basename(fname)}")

if not objpoints:
    print("Error: No se detectaron tableros en ninguna imagen. Aseg√∫rate de que las im√°genes sean correctas.")
    exit()

# --- 4. CALIBRACI√ìN DE LA C√ÅMARA ---
h, w = gray.shape
ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(
    objpoints,
    imgpoints,
    (w, h),
    None,
    None
)

print("\n--- RESULTADOS DE LA CALIBRACI√ìN ---")
print("‚úÖ Calibraci√≥n Finalizada!")
print("\nMatriz Intr√≠nseca (K):\n", mtx)
print("\nCoeficientes de Distorsi√≥n:\n", dist)
print("\nError de Reproyecci√≥n Total (promedio):", ret)

# --- 5. GUARDAR PAR√ÅMETROS DE CALIBRACI√ìN ---
calib_filename = 'calibracion_camara.npz'
np.savez(calib_filename, mtx=mtx, dist=dist, rvecs=rvecs, tvecs=tvecs)
print(f"\nPar√°metros de calibraci√≥n guardados en '{calib_filename}'")


# --- 6. VISUALIZACI√ìN DE LA CORRECCI√ìN DE DISTORSI√ìN CON PUNTOS DE REPROYECCI√ìN ---
if found_images:
    # Elegimos una imagen de prueba del conjunto de calibraci√≥n (ej: la del medio)
    img_test_path = found_images[len(found_images) // 2]
    img_original = cv2.imread(img_test_path)
    if img_original is None:
        print(f"Error: No se pudo cargar la imagen de prueba {img_test_path}.")
        exit()

    gray_test = cv2.cvtColor(img_original, cv2.COLOR_BGR2GRAY)
    ret_test, corners_original = cv2.findChessboardCorners(gray_test, CHESSBOARD_SIZE, None)

    if ret_test:
        corners_original_refined = cv2.cornerSubPix(gray_test, corners_original, (11,11), (-1,-1), criteria)

        # Corregir la distorsi√≥n de la imagen
        mapx, mapy = cv2.initUndistortRectifyMap(mtx, dist, None, mtx, (w,h), 5)
        dst = cv2.remap(img_original.copy(), mapx, mapy, cv2.INTER_LINEAR) # Usar .copy() para no modificar el original

        # Calcular la pose de la c√°mara para esta imagen de prueba
        ret_pose, rvec_test, tvec_test = cv2.solvePnP(objp, corners_original_refined, mtx, dist)

        # Proyectar los puntos 3D del tablero (objp) de nuevo en la imagen
        # Esto nos da los puntos 2D corregidos (c√≥mo deber√≠an verse sin distorsi√≥n)
        imgpts_corrected, _ = cv2.projectPoints(objp, rvec_test, tvec_test, mtx, dist)
        
        # --- Dibujar en las im√°genes ---
        # Dibujar las esquinas detectadas originalmente en la imagen original (distorsionada)
        img_with_original_corners = img_original.copy()
        cv2.drawChessboardCorners(img_with_original_corners, CHESSBOARD_SIZE, corners_original_refined, ret_test)
        
        # Dibujar los puntos corregidos (reproyectados) en la imagen corregida
        img_with_corrected_corners = dst.copy()
        # Dibujar c√≠rculos para los puntos corregidos
        for corner in imgpts_corrected:
            x, y = int(corner[0][0]), int(corner[0][1])
            cv2.circle(img_with_corrected_corners, (x, y), 5, (0, 255, 0), -1) # C√≠rculos verdes
        # Opcional: Dibujar las l√≠neas que unen estos puntos corregidos
        for i in range(CHESSBOARD_SIZE[1]): # Filas
            for j in range(CHESSBOARD_SIZE[0] - 1): # Columnas
                p1_idx = i * CHESSBOARD_SIZE[0] + j
                p2_idx = i * CHESSBOARD_SIZE[0] + j + 1
                p1 = tuple(imgpts_corrected[p1_idx][0].astype(int))
                p2 = tuple(imgpts_corrected[p2_idx][0].astype(int))
                cv2.line(img_with_corrected_corners, p1, p2, (0, 255, 255), 2) # L√≠neas horizontales (amarillas)
        for i in range(CHESSBOARD_SIZE[1] - 1): # Filas
            for j in range(CHESSBOARD_SIZE[0]): # Columnas
                p1_idx = i * CHESSBOARD_SIZE[0] + j
                p2_idx = (i + 1) * CHESSBOARD_SIZE[0] + j
                p1 = tuple(imgpts_corrected[p1_idx][0].astype(int))
                p2 = tuple(imgpts_corrected[p2_idx][0].astype(int))
                cv2.line(img_with_corrected_corners, p1, p2, (255, 0, 255), 2) # L√≠neas verticales (magenta)


        # Mostrar original y corregida lado a lado con las marcas
        plt.figure(figsize=(14, 7))
        plt.subplot(1, 2, 1)
        plt.imshow(cv2.cvtColor(img_with_original_corners, cv2.COLOR_BGR2RGB))
        plt.title('Original (Puntos detectados)')
        plt.axis('off')

        plt.subplot(1, 2, 2)
        plt.imshow(cv2.cvtColor(img_with_corrected_corners, cv2.COLOR_BGR2RGB))
        plt.title('Corregida (Puntos reproyectados)')
        plt.axis('off')
        plt.suptitle(f"Comparaci√≥n de Distorsi√≥n y Reproyecci√≥n (Imagen: {os.path.basename(img_test_path)})")
        plt.show()

        output_corrected_img = 'resultado_corregido_ejemplo_con_puntos.png'
        cv2.imwrite(output_corrected_img, img_with_corrected_corners)
        print(f"Imagen corregida de ejemplo con puntos guardada en '{output_corrected_img}'")

    else:
        print(f"Advertencia: No se pudo detectar el tablero en la imagen de prueba {img_test_path} para visualizaci√≥n detallada.")
else:
    print("\nNo hay im√°genes para mostrar la correcci√≥n de distorsi√≥n.")


# --- 7. VISUALIZACI√ìN 3D DE LAS POSES DEL TABLERO (C√°mara en el origen) ---

fig = plt.figure(figsize=(10, 8))
ax = fig.add_subplot(111, projection='3d')

# Dibujar la c√°mara fija en el origen del sistema de coordenadas del mundo
ax.scatter(0, 0, 0, marker='o', color='purple', s=100, label='C√°mara (Fija en Origen)')
ax.quiver(0, 0, 0, SQUARE_SIZE_MM, 0, 0, color='r', length=2*SQUARE_SIZE_MM, arrow_length_ratio=0.3) # Eje X de la c√°mara
ax.quiver(0, 0, 0, 0, SQUARE_SIZE_MM, 0, color='g', length=2*SQUARE_SIZE_MM, arrow_length_ratio=0.3) # Eje Y de la c√°mara
ax.quiver(0, 0, 0, 0, 0, SQUARE_SIZE_MM, color='b', length=2*SQUARE_SIZE_MM, arrow_length_ratio=0.3) # Eje Z de la c√°mara
ax.text(SQUARE_SIZE_MM*2.2, 0, 0, 'Cam X', color='r')
ax.text(0, SQUARE_SIZE_MM*2.2, 0, 'Cam Y', color='g')
ax.text(0, 0, SQUARE_SIZE_MM*2.2, 'Cam Z', color='b')


board_centers_x = []
board_centers_y = []
board_centers_z = []

for i in range(len(rvecs)):
    rvec = rvecs[i]
    tvec = tvecs[i]

    R_obj_to_cam, _ = cv2.Rodrigues(rvec)

    transformed_board_points = (R_obj_to_cam @ objp.T + tvec).T

    x_coords = transformed_board_points[:, 0]
    y_coords = transformed_board_points[:, 1]
    z_coords = transformed_board_points[:, 2]

    ax.plot_wireframe(x_coords.reshape(CHESSBOARD_SIZE[1], CHESSBOARD_SIZE[0]),
                      y_coords.reshape(CHESSBOARD_SIZE[1], CHESSBOARD_SIZE[0]),
                      z_coords.reshape(CHESSBOARD_SIZE[1], CHESSBOARD_SIZE[0]),
                      color='gray', alpha=0.7, label=f'Tablero {i+1}' if i == 0 else "")

    board_axes_origin = tvec.ravel()
    board_axes_x = (R_obj_to_cam @ np.array([[SQUARE_SIZE_MM*0.5],[0],[0]]) + tvec).ravel()
    board_axes_y = (R_obj_to_cam @ np.array([[0],[SQUARE_SIZE_MM*0.5],[0]]) + tvec).ravel()
    board_axes_z = (R_obj_to_cam @ np.array([[0],[0],[-SQUARE_SIZE_MM*0.5]]) + tvec).ravel()
    
    ax.quiver(board_axes_origin[0], board_axes_origin[1], board_axes_origin[2],
              board_axes_x[0]-board_axes_origin[0], board_axes_x[1]-board_axes_origin[1], board_axes_x[2]-board_axes_origin[2],
              color='r', length=SQUARE_SIZE_MM*0.5, arrow_length_ratio=0.3)
    ax.quiver(board_axes_origin[0], board_axes_origin[1], board_axes_origin[2],
              board_axes_y[0]-board_axes_origin[0], board_axes_y[1]-board_axes_origin[1], board_axes_y[2]-board_axes_origin[2],
              color='g', length=SQUARE_SIZE_MM*0.5, arrow_length_ratio=0.3)
    ax.quiver(board_axes_origin[0], board_axes_origin[1], board_axes_origin[2],
              board_axes_z[0]-board_axes_origin[0], board_axes_z[1]-board_axes_origin[1], board_axes_z[2]-board_axes_origin[2],
              color='b', length=SQUARE_SIZE_MM*0.5, arrow_length_ratio=0.3)
    
    board_centers_x.append(board_axes_origin[0])
    board_centers_y.append(board_axes_origin[1])
    board_centers_z.append(board_axes_origin[2])


ax.set_xlabel('X (mm)')
ax.set_ylabel('Y (mm)')
ax.set_zlabel('Z (mm)')
ax.set_title('Poses del Tablero respecto a la C√°mara Fija')
ax.legend()

all_coords = []
if board_centers_x:
    all_coords.extend(board_centers_x)
    all_coords.extend(board_centers_y)
    all_coords.extend(board_centers_z)
    all_coords = np.array(all_coords)

    if all_coords.size > 0:
        max_range = np.array([np.max(all_coords)-np.min(all_coords)]).max() / 2.0
        mid_x = (np.max(board_centers_x)+np.min(board_centers_x)) / 2.0
        mid_y = (np.max(board_centers_y)+np.min(board_centers_y)) / 2.0
        mid_z = (np.max(board_centers_z)+np.min(board_centers_z)) / 2.0

        mid_x = (mid_x + 0) / 2
        mid_y = (mid_y + 0) / 2
        mid_z = (mid_z + 0) / 2

        ax.set_xlim(mid_x - max_range, mid_x + max_range)
        ax.set_ylim(mid_y - max_range, mid_y + max_range)
        ax.set_zlim(mid_z - max_range, mid_z + max_range)

plt.show()

print("\nVisualizaci√≥n 3D de las poses del tablero (c√°mara fija) completada.")
```

<figure>
  <img src="resultado_corregido_ejemplo_con_puntos.png" alt="Fig6." />
  <figcaption> Fig.6 Ejemplo de la correci√≥n de la distorsi√≥n.</figcaption>
</figure>

## Conclusiones 

1.  **La Calibraci√≥n es Fundamental para la Percepci√≥n Geom√©trica Precisa:**
    * Hemos demostrado que la calibraci√≥n de una c√°mara no es un paso opcional, sino esencial para cualquier aplicaci√≥n de visi√≥n por computadora que requiera mediciones precisas, reconstrucci√≥n 3D o comprensi√≥n espacial del entorno. Sin ella, la c√°mara es solo un sensor de luz; con ella, se convierte en un instrumento de medici√≥n.

2.  **Correcci√≥n de la Distorsi√≥n de la Lente:**
    * Las lentes reales introducen distorsiones (principalmente radiales y tangenciales) que curvan las l√≠neas rectas y alteran la percepci√≥n de la geometr√≠a. La calibraci√≥n nos permite cuantificar estas distorsiones mediante los coeficientes de distorsi√≥n (`dist`).
    * La visualizaci√≥n de la imagen original vs. la corregida, con las l√≠neas del tablero, ilustra de forma contundente c√≥mo la calibraci√≥n "endereza" el mundo, transformando las l√≠neas curvas en segmentos rectos, lo que es vital para una representaci√≥n fiel de la realidad.

3.  **Determinaci√≥n de los Par√°metros Intr√≠nsecos (`K`):**
    * La matriz intr√≠nseca (`mtx`) de la c√°mara encapsula sus propiedades internas, como la distancia focal efectiva (`fx`, `fy`) y el punto principal (`cx`, `cy`). Estos par√°metros son √∫nicos para cada c√°mara y lente.
    * Conociendo `K`, podemos traducir las coordenadas de p√≠xeles a rayos 3D en el espacio de la c√°mara, un paso fundamental para la triangulaci√≥n y la reconstrucci√≥n 3D.

4.  **Estimaci√≥n de la Pose Relativa (Par√°metros Extr√≠nsecos):**
    * La calibraci√≥n no solo nos da los par√°metros intr√≠nsecos y de distorsi√≥n, sino que tambi√©n nos proporciona los par√°metros extr√≠nsecos (`rvecs` y `tvecs`) para cada imagen utilizada. Estos describen la rotaci√≥n y traslaci√≥n de la c√°mara con respecto al objeto de calibraci√≥n (el tablero).
    * La visualizaci√≥n 3D interactiva nos permiti√≥ ver las diferentes poses del tablero en relaci√≥n con la c√°mara fija. Esto no solo ayuda a entender los datos de calibraci√≥n, sino que tambi√©n valida la diversidad de las capturas, crucial para una calibraci√≥n robusta.

5.  **Importancia de la Adquisici√≥n de Datos:**
    * La calidad de la calibraci√≥n depende directamente de la calidad y variedad de las im√°genes del tablero. M√∫ltiples tomas desde diversos √°ngulos, distancias y orientaciones son esenciales para que el algoritmo de calibraci√≥n pueda "ver" y modelar con precisi√≥n las distorsiones de toda la lente.
    * El script de adquisici√≥n autom√°tica basado en movimiento es una herramienta valiosa para asegurar esta diversidad en los datos de entrada, minimizando la redundancia y maximizando la eficiencia.

6.  **Base para Aplicaciones Avanzadas:**
    * Una c√°mara calibrada es el punto de partida para una multitud de aplicaciones avanzadas de visi√≥n por computadora:
        * **Reconstrucci√≥n 3D:** Construir modelos 3D de objetos o entornos.
        * **Realidad Aumentada (AR):** Superponer objetos virtuales de forma realista en el mundo real.
        * **Rob√≥tica:** Permitir que los robots perciban su entorno con precisi√≥n para navegaci√≥n y manipulaci√≥n.
        * **Metrolog√≠a:** Realizar mediciones exactas de objetos en im√°genes.
        * **Visi√≥n Est√©reo:** Calibrar m√∫ltiples c√°maras para percibir la profundidad.

En resumen, la calibraci√≥n de c√°mara transforma un dispositivo de captura de luz en un sensor geom√©trico preciso. Este proceso, aunque matem√°tico, es fundamental para "ense√±ar a ver" a las m√°quinas de una manera que les permita entender y medir el mundo f√≠sico con la fidelidad necesaria para tareas complejas.





